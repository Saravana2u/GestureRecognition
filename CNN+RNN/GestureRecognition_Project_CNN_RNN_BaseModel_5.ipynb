{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0f5dc3-9463-451f-8fcd-9b6d958b0338",
   "metadata": {},
   "source": [
    "# Gesture Recognition CNN + RNN\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1313024-24fc-49d5-b07c-3530531120c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread, imresize\n",
    "import imageio\n",
    "#img = imageio.imread('your_image.jpg')\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "#CNN\n",
    "from tensorflow import keras\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras import layers, optimizers\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.layers import Input, Add,Dropout, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.models import Model, load_model\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.preprocessing import image\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.utils import plot_model\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.initializers import glorot_uniform\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.applications import ResNet50\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "\n",
    "#RNN -includes\n",
    "from nltk.corpus import brown\t\t\t\t\t\n",
    "from nltk.corpus import treebank\t\t\t\t\t\n",
    "from nltk.corpus import conll2000\t\t\t\t\t\n",
    "import seaborn as sns\t\t\t\t\t\n",
    "from gensim.models import KeyedVectors\t\t\t\t\t\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\t\t\t\t\t\n",
    "from tensorflow.keras.utils import to_categorical\t\t\t\t\t\n",
    "from tensorflow.keras import Sequential, Input, Model\t\t\t\t\t\n",
    "from tensorflow.keras.layers import Embedding, Dense, TimeDistributed, LSTM, GRU, Bidirectional, SimpleRNN, RNN\t\t\t\t\t\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\t\t\t\t\t\n",
    "from sklearn.model_selection import train_test_split\t\t\t\t\t\n",
    "from sklearn.utils import shuffle\t\t\t\t\t\n",
    "\n",
    "\n",
    "#common includes\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, LSTM, Dense, GlobalAveragePooling2D\n",
    "\n",
    "import cv2\n",
    "# Read the image\n",
    "#img = cv2.imread('image.jpg')\n",
    "# Resize the image to half its original size\n",
    "#resized_img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "# Resize the image to a specific size (300x200 pixels)\n",
    "#resized_img = cv2.resize(img, (300, 200))\n",
    "# Display the resized image\n",
    "#cv2.imshow('Resized Image', resized_img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a5b2de-aed8-4de2-8601-07ff4a80d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d943c8b-392e-40ff-9c75-354ebd63198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "#tf.set_random_seed(30)\n",
    "tf.random.set_seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a1721-5fdc-4557-bec1-ea2f9945cd2e",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fda51b2-754d-4e53-b41c-fecea5683e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Gesture_Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Gesture_Project_data/val.csv').readlines())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c61148-2ed8-4c68-a83f-55cdb12345b1",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25c6fd9-0fae-44e8-be93-4ce6156d4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = [num for num in range(30)]\n",
    "#img_idx =  img_idx[::2]\n",
    "#img_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc91cd9a-04ff-4c4e-9c4f-4f8ccf75fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Dimen : 30\n"
     ]
    }
   ],
   "source": [
    "new_width  =  120\n",
    "new_height = 120\n",
    "#img_idx = [num for num in range(30)]\n",
    "#img_idx =  img_idx[::5] #only 5 images to start with\n",
    "time_dimen = len(img_idx)\n",
    "print(\"Time Dimen :\", time_dimen)\n",
    "#num_batches = 50\n",
    "batch_size = 50 #experiment with the batch size\n",
    "num_channels = 3\n",
    "num_classes = 5\n",
    "num_epochs = 50 # It should be 50 / 100\n",
    "train_path = './Gesture_Project_data/train'\n",
    "val_path = './Gesture_Project_data/val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98756d0-5a18-4808-8587-713f357aa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, total_seq) : \n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    #create a list of image numbers you want to use for a particular video\n",
    "    #img_idx = img_idx = [num for num in range(30)]\n",
    "    #img_idx =  img_idx[::5] #only 5 images to start with\n",
    "    img_idx = [num for num in range(30)]\n",
    "    img_idx =  img_idx[::5] #only 5 images to start with\n",
    "    time_dimen = len(img_idx)\n",
    "    img_idx = img_idx\n",
    "    #num_batches = (int) (total_seq / batch_size )\n",
    "    new_width  =  120\n",
    "    new_height = 120\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = (int) (total_seq / batch_size ) # start with 1 batch once --calculate the number of batches\n",
    "        #print(\"Num Batches :\",num_batches)\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            #batch_size - Batch Size / Number of batches\n",
    "            #x - Number of images / Number of time steps in video sequence\n",
    "            #y - image size x\n",
    "            #z - image size y\n",
    "            #3 - RGB channel\n",
    "            x = time_dimen\n",
    "            y = new_height\n",
    "            z = new_height\n",
    "            #print(\"batch :\",batch)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,num_classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                #print(\"batch*batch_size : \",batch*batch_size)\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = cv2.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item])\n",
    "                    image = cv2.resize(image, (new_width, new_height))\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    # Convert the image to float32\n",
    "                    image = image.astype(np.float32)\n",
    "                    # Normalize the image to the range [0, 1]\n",
    "                    normalized_img = image / 255.0\n",
    "                    # Display or save the normalized image\n",
    "                    #cv2.imshow('Normalized Image', normalized_img)\n",
    "                    #cv2.waitKey(0)\n",
    "                    #cv2.destroyAllWindows()\n",
    "                    imageR = normalized_img[:, :, 0] \n",
    "                    imageG = normalized_img[:, :, 1] \n",
    "                    imageB = normalized_img[:, :, 2]\n",
    "                    #imageR=imageR.astype(np.float32)\n",
    "                    #imageR = imageR / 255.0\n",
    "                    #imageG=imageG.astype(np.float32)\n",
    "                    #imageG = imageG / 255.0\n",
    "                    #imageB=imageB.astype(np.float32)\n",
    "                    #imageB = imageB / 255.0                    \n",
    "                    batch_data[folder,idx,:,:,0] = imageR  #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = imageG  #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = imageB  #normalise and feed in the image\n",
    "\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "        if (total_seq%batch_size) > 0: #remaining delta elements             \n",
    "            new_batch_size = total_seq%batch_size\n",
    "            #print(\"New Batch Size\",new_batch_size)\n",
    "            x = time_dimen\n",
    "            y = new_height\n",
    "            z = new_height\n",
    "            last_batch_data = np.zeros((new_batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            last_batch_labels = np.zeros((new_batch_size,num_classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(new_batch_size): # iterate over the batch_size\n",
    "                #print(\"num_batches*batch_size : \",num_batches*batch_size)\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = cv2.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item])\n",
    "                    image = cv2.resize(image, (new_width, new_height))\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    # Convert the image to float32\n",
    "                    image = image.astype(np.float32)\n",
    "                    # Normalize the image to the range [0, 1]\n",
    "                    normalized_img = image / 255.0\n",
    "                    # Display or save the normalized image\n",
    "                    #cv2.imshow('Normalized Image', normalized_img)\n",
    "                    #cv2.waitKey(0)\n",
    "                    #cv2.destroyAllWindows()\n",
    "                    imageR = normalized_img[:, :, 0] \n",
    "                    imageG = normalized_img[:, :, 1] \n",
    "                    imageB = normalized_img[:, :, 2]\n",
    "                    #imageR=imageR.astype(np.float32)\n",
    "                    #imageR = imageR / 255.0\n",
    "                    #imageG=imageG.astype(np.float32)\n",
    "                    #imageG = imageG / 255.0\n",
    "                    #imageB=imageB.astype(np.float32)\n",
    "                    #imageB = imageB / 255.0                    \n",
    "                    last_batch_data[folder,idx,:,:,0] = imageR  #normalise and feed in the image\n",
    "                    last_batch_data[folder,idx,:,:,1] = imageG  #normalise and feed in the image\n",
    "                    last_batch_data[folder,idx,:,:,2] = imageB  #normalise and feed in the image\n",
    "                last_batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
    "                #print(\"Last Batch Lables : \",batch_labels)\n",
    "            yield last_batch_data, last_batch_labels #you yield the batch_data and the batch_labels, remember what does yield do        \n",
    "        # write the code for the remaining data points which are left after full batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441ca65d-7972-4b83-b946-d7d4b22166f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size, len(train_doc))\n",
    "val_generator = generator(val_path, val_doc, batch_size, len(val_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09400f10-1ece-4e08-b2ff-881167863f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Num of Training Batches : 14\n",
      "Source path =  ./Gesture_Project_data/train ; batch size = 50\n",
      "Last Batch Size of batch_data: 13\n",
      "Last Batch Size of batch_labels 13\n",
      "Total Number of Validation Batches : 2\n",
      "Source path =  ./Gesture_Project_data/val ; batch size = 50\n",
      "Last Batch Size of batch_data: 50\n",
      "Last Batch Size of batch_labels 50\n"
     ]
    }
   ],
   "source": [
    "# Test the Generator code\n",
    "total_seq = len(train_doc) # total number of data sets\n",
    "total_num_batches= 0 ;\n",
    "if (total_seq%batch_size) == 0:\n",
    "    total_num_batches =(int) (total_seq/batch_size)\n",
    "else:\n",
    "    total_num_batches = (total_seq//batch_size) + 1\n",
    "    \n",
    "print(\"Total Num of Training Batches :\",total_num_batches)\n",
    "batch_data = []\n",
    "for count in range(total_num_batches) : \n",
    "    batch_data = next(train_generator)\n",
    "print(\"Last Batch Size of batch_data:\",len(batch_data[0]))\n",
    "print(\"Last Batch Size of batch_labels\",len(batch_data[1]))\n",
    "# Test the Generator code\n",
    "total_seq = len(val_doc) # total number of data sets\n",
    "total_num_batches= 0 ;\n",
    "if (total_seq%batch_size) == 0:\n",
    "    total_num_batches =(int) (total_seq/batch_size)\n",
    "else:\n",
    "    total_num_batches = (total_seq//batch_size) + 1\n",
    "    \n",
    "print(\"Total Number of Validation Batches :\",total_num_batches)\n",
    "batch_data = []\n",
    "for count in range(total_num_batches) : \n",
    "    batch_data = next(val_generator)\n",
    "print(\"Last Batch Size of batch_data:\",len(batch_data[0]))\n",
    "print(\"Last Batch Size of batch_labels\",len(batch_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb30654-c211-4641-8353-9ad3bed2d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 50\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 50\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed522047-b632-4345-ad66-696b0e67e50b",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7673e-e181-4410-bac4-9ce10056b19a",
   "metadata": {},
   "source": [
    "\n",
    "Now that you have written the model, the next step is to compile the model. When you print the summary of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e261b7a-4b83-41c6-91da-acfd5dd95a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 50\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)       [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, None, None, 3)        0         ['input_14[0][0]']            \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, None, None, 64)       9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, None, None, 64)       256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, None, None, 64)       0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, None, None, 64)       0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, None, None, 64)       0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, None, None, 64)       4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, None, None, 256)      16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, None, None, 256)      0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, None, None, 256)      0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, None, None, 256)      0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, None, None, 256)      0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, None, None, 256)      0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, None, None, 256)      0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, None, None, 128)      32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, None, None, 512)      131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, None, None, 512)      0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, None, None, 512)      0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, None, None, 512)      0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, None, None, 512)      0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, None, None, 512)      0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, None, None, 512)      0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, None, None, 512)      0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, None, None, 512)      0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, None, None, 256)      131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, None, None, 1024)     525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, None, None, 1024)     0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, None, None, 1024)     0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, None, None, 1024)     0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, None, None, 1024)     0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, None, None, 1024)     0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, None, None, 1024)     0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, None, None, 1024)     0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, None, None, 1024)     0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, None, None, 1024)     0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, None, None, 1024)     0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, None, None, 512)      524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, None, None, 2048)     2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, None, None, 2048)     0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, None, None, 2048)     0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, None, None, 2048)     0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, None, None, 2048)     0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, None, None, 64)       1179712   ['conv5_block3_out[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, None, None, 64)       0         ['conv2d_8[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, None, None, 64)       36928     ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, None, None, 64)       0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4  (None, 64)                   0         ['max_pooling2d_9[0][0]']     \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 2000)                 130000    ['global_average_pooling2d_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24934352 (95.12 MB)\n",
      "Trainable params: 1346640 (5.14 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n",
      "Number of features extracted: 2000\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, None, None, Non   0         \n",
      "                             e, 3)]                              \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, None, 2000)        24934352  \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, None, 256)         2311168   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, None, 128)         197120    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27492373 (104.88 MB)\n",
      "Trainable params: 3904661 (14.90 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN Layers\n",
    "#A 3D convolutional layer expects a 5D input tensor with the shape: (batch_size, time_steps, height, width, channels).\t\t\t\n",
    "# Here we are using ResNet50 as base pretrained model\t\t\t\n",
    "\n",
    "# Define the input layer -- we need 5 D tensor : time, batch, image height, image weight, color channels with batch size)\n",
    "print(\"Batch Size:\",batch_size)\n",
    "input_layer = Input(shape=(time_dimen, new_width, new_height, 3), batch_size=batch_size)  # None is the sequence length (time_steps)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# As we are using ResNet model only for feature extraction and not adjusting the weights\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "for layer in base_model.layers:\t\t\t\t\t\t\t\t\t\t\t\t\n",
    " \tlayer.trainable = False\t\n",
    "\n",
    "# we freeze the first 40 layers in base model\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#for layer in base_model.layers[:40]:  # Adjust number based on architecture\n",
    "#    layer.trainable = False\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "# Get base model output \t\t\t\t\t\t\t\t\t\t\t\t\n",
    "base_model_ouput = base_model.output\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Adding our own layer \t\n",
    "\n",
    "# Adding our own CNN layers\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(base_model_ouput)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# x = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Adding GlobalAveragePooling and Fully Connected layers\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "# Adding fully connected layer\n",
    "#x=Conv2D(32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = Dense(2000, activation='relu')(x)\n",
    "cnn_model = Model(inputs=base_model.input, outputs=x)\t\n",
    "\n",
    "# Print CNN model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "# Access the output shape CNN layer\n",
    "layer_output_shape = cnn_model.layers[-1].output_shape\n",
    "num_features = layer_output_shape[-1]  # Last dimension is the number of features\n",
    "print(\"Number of features extracted:\", num_features)\n",
    "\n",
    "\n",
    "# Input layer for TimeDistributed\n",
    "input_layer = Input(shape=(None, *base_model.input_shape[1:]))\n",
    "\n",
    "# Apply CNN to each frame in the sequence using TimeDistributed\n",
    "time_distributed_cnn = TimeDistributed(cnn_model)\n",
    "extracted_features = time_distributed_cnn(input_layer)  # Connect to the input layer\n",
    "\n",
    "# Apply CNN to each frame in the sequence using TimeDistributed\n",
    "#time_distributed_cnn = TimeDistributed(cnn_model)\n",
    "#extracted_features = time_distributed_cnn(input_layer)  # Connect to the input layer\n",
    "\n",
    "\n",
    "# Add stacked LSTM layers for temporal modeling \n",
    "lstm_layer1 = LSTM(256, return_sequences=True, stateful=False)(extracted_features) \n",
    "lstm_layer2 = LSTM(128, return_sequences=True, stateful=False)(lstm_layer1)        # Stacked LSTM\n",
    "lstm_layer3 = LSTM(64, return_sequences=False, stateful=False)(lstm_layer2)        # Final LSTM, no sequence output\n",
    " \n",
    "\n",
    "# Classification Layer\n",
    "num_classes = num_classes  # Replace with the number of classes in your dataset\n",
    "output_layer = Dense(num_classes, activation='softmax')(lstm_layer3)\n",
    "\n",
    "# Wrap CNN in TimeDistributed to handle sequences of frames\n",
    "#time_distributed_cnn = TimeDistributed(cnn_model)\n",
    "\n",
    "# Define and compile the model CNN + RNN with 5 dimentional tensors\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print CNN+RNN model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc53aaa-9313-4459-8e3e-97fcfb9be3b6",
   "metadata": {},
   "source": [
    "\n",
    "Let us create the train_generator and the val_generator which will be used in .fit_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c975b068-6d84-4afb-969f-4cfff6df708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator = generator(train_path, train_doc, batch_size)\n",
    "#val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "326dea23-bdbd-422b-99e6-c73e5845ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = 'd:\\\\' + model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\n",
    "\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n",
    "\n",
    "# write the REducelronplateau code here\n",
    "#LR = 0.01\n",
    "#callbacks_list = [checkpoint, LR]\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "#model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', save_best_only=True)\n",
    "callbacks_list = [early_stopping, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d79a74d4-fa03-4e63-a411-52ee346dff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\model_init_2024-12-0520_29_22.001437/model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras\n"
     ]
    }
   ],
   "source": [
    "print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6905d8d-9a80-47dd-ab26-71cf16240088",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e632cc3a-ee08-4fa5-88d1-a1372532cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd9b95d-b15d-4ab2-af97-f84bb030121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch, num of training sequences and batch size :  14 663 50\n",
      "Steps per epoch, num of validation sequences and batch size :  2 100 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Steps per epoch, num of training sequences and batch size : \",steps_per_epoch,num_train_sequences,batch_size)\n",
    "print(\"Steps per epoch, num of validation sequences and batch size : \",validation_steps,num_val_sequences,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350164-a950-4646-9187-1b550ca7a5db",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac05c0f5-dc57-42b9-98e2-993f6fd0300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.6133 - categorical_accuracy: 0.2097\n",
      "Epoch 1: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00001-1.61330-0.20965-1.55861-0.27000.keras\n",
      "14/14 [==============================] - 52s 3s/step - loss: 1.6133 - categorical_accuracy: 0.2097 - val_loss: 1.5586 - val_categorical_accuracy: 0.2700\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4850 - categorical_accuracy: 0.3318\n",
      "Epoch 2: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00002-1.48502-0.33183-1.49365-0.31000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.4850 - categorical_accuracy: 0.3318 - val_loss: 1.4936 - val_categorical_accuracy: 0.3100\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4408 - categorical_accuracy: 0.3122\n",
      "Epoch 3: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00003-1.44077-0.31222-1.39238-0.33000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.4408 - categorical_accuracy: 0.3122 - val_loss: 1.3924 - val_categorical_accuracy: 0.3300\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3777 - categorical_accuracy: 0.3575\n",
      "Epoch 4: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00004-1.37771-0.35747-1.39143-0.37000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.3777 - categorical_accuracy: 0.3575 - val_loss: 1.3914 - val_categorical_accuracy: 0.3700\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3984 - categorical_accuracy: 0.3650\n",
      "Epoch 5: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00005-1.39844-0.36501-1.38685-0.39000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.3984 - categorical_accuracy: 0.3650 - val_loss: 1.3869 - val_categorical_accuracy: 0.3900\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3656 - categorical_accuracy: 0.3816\n",
      "Epoch 6: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00006-1.36561-0.38160-1.43603-0.33000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.3656 - categorical_accuracy: 0.3816 - val_loss: 1.4360 - val_categorical_accuracy: 0.3300\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3825 - categorical_accuracy: 0.3801\n",
      "Epoch 7: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00007-1.38249-0.38009-1.33450-0.36000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.3825 - categorical_accuracy: 0.3801 - val_loss: 1.3345 - val_categorical_accuracy: 0.3600\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3887 - categorical_accuracy: 0.3861\n",
      "Epoch 8: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00008-1.38872-0.38612-1.41372-0.37000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.3887 - categorical_accuracy: 0.3861 - val_loss: 1.4137 - val_categorical_accuracy: 0.3700\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3724 - categorical_accuracy: 0.4103\n",
      "Epoch 9: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00009-1.37245-0.41026-1.36332-0.33000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.3724 - categorical_accuracy: 0.4103 - val_loss: 1.3633 - val_categorical_accuracy: 0.3300\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3118 - categorical_accuracy: 0.4133\n",
      "Epoch 10: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00010-1.31179-0.41327-1.36844-0.38000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.3118 - categorical_accuracy: 0.4133 - val_loss: 1.3684 - val_categorical_accuracy: 0.3800\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2676 - categorical_accuracy: 0.4284\n",
      "Epoch 11: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00011-1.26762-0.42836-1.34304-0.40000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.2676 - categorical_accuracy: 0.4284 - val_loss: 1.3430 - val_categorical_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2496 - categorical_accuracy: 0.4163\n",
      "Epoch 12: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00012-1.24958-0.41629-1.31849-0.35000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.2496 - categorical_accuracy: 0.4163 - val_loss: 1.3185 - val_categorical_accuracy: 0.3500\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2318 - categorical_accuracy: 0.4374\n",
      "Epoch 13: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00013-1.23181-0.43741-1.31960-0.41000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.2318 - categorical_accuracy: 0.4374 - val_loss: 1.3196 - val_categorical_accuracy: 0.4100\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1992 - categorical_accuracy: 0.4706\n",
      "Epoch 14: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00014-1.19918-0.47059-1.36479-0.45000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.1992 - categorical_accuracy: 0.4706 - val_loss: 1.3648 - val_categorical_accuracy: 0.4500\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2463 - categorical_accuracy: 0.4374\n",
      "Epoch 15: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00015-1.24633-0.43741-1.52610-0.36000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.2463 - categorical_accuracy: 0.4374 - val_loss: 1.5261 - val_categorical_accuracy: 0.3600\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2209 - categorical_accuracy: 0.4525\n",
      "Epoch 16: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00016-1.22087-0.45249-1.38798-0.38000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.2209 - categorical_accuracy: 0.4525 - val_loss: 1.3880 - val_categorical_accuracy: 0.3800\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1648 - categorical_accuracy: 0.4872\n",
      "Epoch 17: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00017-1.16484-0.48718-1.32977-0.40000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.1648 - categorical_accuracy: 0.4872 - val_loss: 1.3298 - val_categorical_accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1275 - categorical_accuracy: 0.4947\n",
      "Epoch 18: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00018-1.12753-0.49472-1.45181-0.38000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.1275 - categorical_accuracy: 0.4947 - val_loss: 1.4518 - val_categorical_accuracy: 0.3800\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1791 - categorical_accuracy: 0.4646\n",
      "Epoch 19: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00019-1.17912-0.46456-1.31661-0.35000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.1791 - categorical_accuracy: 0.4646 - val_loss: 1.3166 - val_categorical_accuracy: 0.3500\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0831 - categorical_accuracy: 0.5143\n",
      "Epoch 20: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00020-1.08310-0.51433-1.33962-0.46000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0831 - categorical_accuracy: 0.5143 - val_loss: 1.3396 - val_categorical_accuracy: 0.4600\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1953 - categorical_accuracy: 0.4781\n",
      "Epoch 21: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00021-1.19525-0.47813-1.29962-0.46000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.1953 - categorical_accuracy: 0.4781 - val_loss: 1.2996 - val_categorical_accuracy: 0.4600\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.2062 - categorical_accuracy: 0.4329\n",
      "Epoch 22: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00022-1.20622-0.43288-1.31537-0.39000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.2062 - categorical_accuracy: 0.4329 - val_loss: 1.3154 - val_categorical_accuracy: 0.3900\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0996 - categorical_accuracy: 0.5309\n",
      "Epoch 23: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00023-1.09962-0.53092-1.32509-0.42000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.0996 - categorical_accuracy: 0.5309 - val_loss: 1.3251 - val_categorical_accuracy: 0.4200\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0625 - categorical_accuracy: 0.5173\n",
      "Epoch 24: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00024-1.06255-0.51735-1.32574-0.38000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.0625 - categorical_accuracy: 0.5173 - val_loss: 1.3257 - val_categorical_accuracy: 0.3800\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0625 - categorical_accuracy: 0.5354\n",
      "Epoch 25: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00025-1.06254-0.53544-1.24638-0.46000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0625 - categorical_accuracy: 0.5354 - val_loss: 1.2464 - val_categorical_accuracy: 0.4600\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.1561 - categorical_accuracy: 0.5038\n",
      "Epoch 26: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00026-1.15610-0.50377-1.46304-0.35000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.1561 - categorical_accuracy: 0.5038 - val_loss: 1.4630 - val_categorical_accuracy: 0.3500\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0761 - categorical_accuracy: 0.5324\n",
      "Epoch 27: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00027-1.07608-0.53243-1.31444-0.42000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0761 - categorical_accuracy: 0.5324 - val_loss: 1.3144 - val_categorical_accuracy: 0.4200\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0794 - categorical_accuracy: 0.5173\n",
      "Epoch 28: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00028-1.07943-0.51735-1.45172-0.38000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0794 - categorical_accuracy: 0.5173 - val_loss: 1.4517 - val_categorical_accuracy: 0.3800\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0310 - categorical_accuracy: 0.5641\n",
      "Epoch 29: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00029-1.03101-0.56410-1.50826-0.32000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0310 - categorical_accuracy: 0.5641 - val_loss: 1.5083 - val_categorical_accuracy: 0.3200\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0881 - categorical_accuracy: 0.5173\n",
      "Epoch 30: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00030-1.08811-0.51735-1.23829-0.46000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0881 - categorical_accuracy: 0.5173 - val_loss: 1.2383 - val_categorical_accuracy: 0.4600\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9966 - categorical_accuracy: 0.5837\n",
      "Epoch 31: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00031-0.99663-0.58371-1.38022-0.40000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.9966 - categorical_accuracy: 0.5837 - val_loss: 1.3802 - val_categorical_accuracy: 0.4000\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0055 - categorical_accuracy: 0.5626\n",
      "Epoch 32: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00032-1.00549-0.56259-1.37414-0.43000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0055 - categorical_accuracy: 0.5626 - val_loss: 1.3741 - val_categorical_accuracy: 0.4300\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9686 - categorical_accuracy: 0.5792\n",
      "Epoch 33: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00033-0.96861-0.57919-1.41962-0.37000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.9686 - categorical_accuracy: 0.5792 - val_loss: 1.4196 - val_categorical_accuracy: 0.3700\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0265 - categorical_accuracy: 0.5611\n",
      "Epoch 34: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00034-1.02648-0.56109-1.30575-0.41000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0265 - categorical_accuracy: 0.5611 - val_loss: 1.3057 - val_categorical_accuracy: 0.4100\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0363 - categorical_accuracy: 0.5551\n",
      "Epoch 35: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00035-1.03635-0.55505-1.54199-0.41000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0363 - categorical_accuracy: 0.5551 - val_loss: 1.5420 - val_categorical_accuracy: 0.4100\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9992 - categorical_accuracy: 0.5626\n",
      "Epoch 36: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00036-0.99918-0.56259-1.34662-0.46000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.9992 - categorical_accuracy: 0.5626 - val_loss: 1.3466 - val_categorical_accuracy: 0.4600\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0270 - categorical_accuracy: 0.5460\n",
      "Epoch 37: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00037-1.02704-0.54600-1.32929-0.47000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.0270 - categorical_accuracy: 0.5460 - val_loss: 1.3293 - val_categorical_accuracy: 0.4700\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9796 - categorical_accuracy: 0.5913\n",
      "Epoch 38: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00038-0.97956-0.59125-1.32582-0.44000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.9796 - categorical_accuracy: 0.5913 - val_loss: 1.3258 - val_categorical_accuracy: 0.4400\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8328 - categorical_accuracy: 0.6486\n",
      "Epoch 39: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00039-0.83283-0.64857-1.47793-0.45000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.8328 - categorical_accuracy: 0.6486 - val_loss: 1.4779 - val_categorical_accuracy: 0.4500\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8835 - categorical_accuracy: 0.6471\n",
      "Epoch 40: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00040-0.88348-0.64706-1.32815-0.47000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.8835 - categorical_accuracy: 0.6471 - val_loss: 1.3281 - val_categorical_accuracy: 0.4700\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8579 - categorical_accuracy: 0.6591\n",
      "Epoch 41: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00041-0.85790-0.65913-1.33363-0.48000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.8579 - categorical_accuracy: 0.6591 - val_loss: 1.3336 - val_categorical_accuracy: 0.4800\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9257 - categorical_accuracy: 0.6199\n",
      "Epoch 42: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00042-0.92569-0.61991-1.35739-0.49000.keras\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.9257 - categorical_accuracy: 0.6199 - val_loss: 1.3574 - val_categorical_accuracy: 0.4900\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9284 - categorical_accuracy: 0.6018\n",
      "Epoch 43: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00043-0.92841-0.60181-1.34786-0.48000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.9284 - categorical_accuracy: 0.6018 - val_loss: 1.3479 - val_categorical_accuracy: 0.4800\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8531 - categorical_accuracy: 0.6395\n",
      "Epoch 44: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00044-0.85309-0.63952-1.50887-0.49000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.8531 - categorical_accuracy: 0.6395 - val_loss: 1.5089 - val_categorical_accuracy: 0.4900\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7873 - categorical_accuracy: 0.6757\n",
      "Epoch 45: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00045-0.78732-0.67572-1.51250-0.46000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.7873 - categorical_accuracy: 0.6757 - val_loss: 1.5125 - val_categorical_accuracy: 0.4600\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7680 - categorical_accuracy: 0.6908\n",
      "Epoch 46: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00046-0.76803-0.69080-1.42910-0.48000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.7680 - categorical_accuracy: 0.6908 - val_loss: 1.4291 - val_categorical_accuracy: 0.4800\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7261 - categorical_accuracy: 0.7044\n",
      "Epoch 47: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00047-0.72606-0.70437-1.52738-0.47000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.7261 - categorical_accuracy: 0.7044 - val_loss: 1.5274 - val_categorical_accuracy: 0.4700\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8363 - categorical_accuracy: 0.6637\n",
      "Epoch 48: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00048-0.83627-0.66365-1.46341-0.52000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.8363 - categorical_accuracy: 0.6637 - val_loss: 1.4634 - val_categorical_accuracy: 0.5200\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6700 - categorical_accuracy: 0.7481\n",
      "Epoch 49: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00049-0.66996-0.74811-1.65454-0.43000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.6700 - categorical_accuracy: 0.7481 - val_loss: 1.6545 - val_categorical_accuracy: 0.4300\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7939 - categorical_accuracy: 0.6938\n",
      "Epoch 50: saving model to d:\\model_init_2024-12-0520_29_22.001437\\model-00050-0.79388-0.69382-1.40039-0.49000.keras\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.7939 - categorical_accuracy: 0.6938 - val_loss: 1.4004 - val_categorical_accuracy: 0.4900\n"
     ]
    }
   ],
   "source": [
    "cnn_rnn_training = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "747ef9f4-0443-4359-9c36-5e7da66572fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise training history\t\t\t\n",
    "plt.plot(cnn_rnn_training.history['categorical_accuracy'])\t\t\t\n",
    "plt.plot(cnn_rnn_training.history['val_categorical_accuracy'])\t\t\t\n",
    "plt.title('model accuracy')\t\t\t\n",
    "plt.ylabel('accuracy')\t\t\t\n",
    "plt.xlabel('epoch')\t\t\t\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\t\t\t\n",
    "plt.show()\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ba725-4e43-42a8-9e7b-eb69787781ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c522a-ec31-46c6-acb7-4dfa709c7d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
